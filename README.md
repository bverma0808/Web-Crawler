# Web-Crawler

A crawler is a program that visits Web sites and reads their pages and other information in order to create entries for a search engine index.
###Features
* Configuration Driven code 
* Easy to setup, easy to run
* No need to compile the code again while changing the CrawlerConfig.txt
* Will automatically create a LinkStore text file for you which will save the visited links

You can visit JavaDocs for the project [here](http://bverma0808.github.io/Web-Crawler/)

Please go through the project wikis to know about how to setup code locally and how to run it.
Diagrams make it easy to understand the whole thing, so [click here](https://cacoo.com/diagrams/agXWl2W4Kn3qw3M3-28152.png) to see its architectural diagram
